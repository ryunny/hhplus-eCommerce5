# Kafka ê¸°ë°˜ ì¿ í° ë°œê¸‰ & ëŒ€ê¸°ì—´ ì‹œìŠ¤í…œ ì„¤ê³„

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­](#ì‹œìŠ¤í…œ-ìš”êµ¬ì‚¬í•­)
3. [ì•„í‚¤í…ì²˜ ì„¤ê³„](#ì•„í‚¤í…ì²˜-ì„¤ê³„)
4. [ì¿ í° ë°œê¸‰ ì‹œìŠ¤í…œ](#ì¿ í°-ë°œê¸‰-ì‹œìŠ¤í…œ)
5. [ëŒ€ê¸°ì—´ ì‹œìŠ¤í…œ](#ëŒ€ê¸°ì—´-ì‹œìŠ¤í…œ)
6. [Kafka íŠ¹ì§• í™œìš© ì „ëµ](#kafka-íŠ¹ì§•-í™œìš©-ì „ëµ)
7. [ì¥ì•  ì²˜ë¦¬ ë° ëª¨ë‹ˆí„°ë§](#ì¥ì• -ì²˜ë¦¬-ë°-ëª¨ë‹ˆí„°ë§)
8. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)

---

## ê°œìš”

### ë°°ê²½
- ì„ ì°©ìˆœ ì¿ í° ì´ë²¤íŠ¸ ì‹œ ëŒ€ëŸ‰ì˜ ë™ì‹œ ìš”ì²­ ë°œìƒ (ì´ˆë‹¹ 10ë§Œ+ ìš”ì²­)
- ê¸°ì¡´ ë™ê¸° ì²˜ë¦¬ ë°©ì‹ì˜ í•œê³„: DB ë¶€í•˜, ì‘ë‹µ ì§€ì—°, ë™ì‹œì„± ì œì–´ ì–´ë ¤ì›€
- Redis ëŒ€ê¸°ì—´ë§Œìœ¼ë¡œëŠ” ì˜ì†ì„± ë° ì¬ì²˜ë¦¬ ë³´ì¥ì´ ì–´ë ¤ì›€

### í•´ê²° ë°©ì•ˆ
Kafkaì˜ í•µì‹¬ íŠ¹ì§•ì„ í™œìš©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜:
1. **Redis**: ë¹ ë¥¸ ì¤‘ë³µ ì²´í¬, ì„ì‹œ ëŒ€ê¸°ì—´
2. **Kafka**: ì˜ì†ì  ë©”ì‹œì§€ í, ìˆœì„œ ë³´ì¥, ì¬ì²˜ë¦¬ ê°€ëŠ¥
3. **Consumer Group**: ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ëŸ‰ ê·¹ëŒ€í™”

---

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
1. **ì„ ì°©ìˆœ ì¿ í° ë°œê¸‰**
   - í•œì •ëœ ìˆ˜ëŸ‰ì˜ ì¿ í°ì„ ì„ ì°©ìˆœìœ¼ë¡œ ë°œê¸‰
   - ì‚¬ìš©ìë‹¹ 1íšŒ ë°œê¸‰ ì œí•œ
   - ë°œê¸‰ ì„±ê³µ/ì‹¤íŒ¨ ì‘ë‹µ

2. **ëŒ€ê¸°ì—´ ê´€ë¦¬**
   - ëŒ€ëŸ‰ íŠ¸ë˜í”½ ìˆ˜ìš© (ì´ˆë‹¹ 10ë§Œ+ ìš”ì²­)
   - ê³µì •í•œ ìˆœì„œ ì²˜ë¦¬ (FIFO)
   - ì‹¤ì‹œê°„ ëŒ€ê¸° ìƒíƒœ ì¡°íšŒ

### ë¹„ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
1. **ì„±ëŠ¥**
   - ì‘ë‹µ ì‹œê°„: 200ms ì´í•˜ (ëŒ€ê¸°ì—´ ì§„ì…)
   - ì²˜ë¦¬ëŸ‰: ì´ˆë‹¹ 10ë§Œ ìš”ì²­ ì´ìƒ
   - ì¿ í° ë°œê¸‰ ì²˜ë¦¬: ì´ˆë‹¹ 1ë§Œ ê±´ ì´ìƒ

2. **ì•ˆì •ì„±**
   - ë©”ì‹œì§€ ìœ ì‹¤ ë°©ì§€ (ìµœì†Œ 1íšŒ ì „ë‹¬ ë³´ì¥)
   - ì¥ì•  ë³µêµ¬ ì‹œ ì¬ì²˜ë¦¬ ê°€ëŠ¥
   - ì¤‘ë³µ ë°œê¸‰ ë°©ì§€

3. **í™•ì¥ì„±**
   - Consumer ìˆ˜í‰ í™•ì¥ ê°€ëŠ¥
   - Kafka íŒŒí‹°ì…˜ ì¦ê°€ë¡œ ì²˜ë¦¬ëŸ‰ ì¦ëŒ€

---

## ì•„í‚¤í…ì²˜ ì„¤ê³„

### ì „ì²´ íë¦„ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â”‚  (ì‚¬ìš©ì)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP POST /coupons/{couponId}/issue
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           API Gateway / Load Balancer           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CouponController (Producer)            â”‚
â”‚  1. Redis ì¤‘ë³µ ì²´í¬ (ì‚¬ìš©ì)                     â”‚
â”‚  2. Redis ì¬ê³  í™•ì¸ (ë‚¨ì€ ìˆ˜ëŸ‰)                  â”‚
â”‚  3. Kafka ì´ë²¤íŠ¸ ë°œí–‰ (CouponIssueRequestedEvent)â”‚
â”‚  4. ì¦‰ì‹œ ì‘ë‹µ (202 Accepted)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ Kafka Topic: coupon.issue.requested
                   â”‚ Key: userId (ê°™ì€ ì‚¬ìš©ìëŠ” ê°™ì€ íŒŒí‹°ì…˜)
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Kafka Broker Cluster               â”‚
â”‚  - Topic: coupon.issue.requested (10 partitions)â”‚
â”‚  - Replication Factor: 3                        â”‚
â”‚  - Message Retention: 7ì¼                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ Consumer Group: coupon-issue-service
                   â”‚ (10ê°œ Consumer ì¸ìŠ¤í„´ìŠ¤)
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     CouponIssueEventHandler (Consumer)          â”‚
â”‚  1. DB ë½ìœ¼ë¡œ ì¿ í° ì¬ê³  í™•ì¸ (ë¹„ê´€ì  ë½)          â”‚
â”‚  2. ì¤‘ë³µ ë°œê¸‰ ì²´í¬ (DB unique ì œì•½)              â”‚
â”‚  3. UserCoupon ìƒì„± (ë°œê¸‰)                       â”‚
â”‚  4. Redis ìºì‹œ ì—…ë°ì´íŠ¸                          â”‚
â”‚  5. ì„±ê³µ/ì‹¤íŒ¨ ì´ë²¤íŠ¸ ë°œí–‰                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”œâ”€ ì„±ê³µ â†’ coupon.issued (ì™¸ë¶€ ì•Œë¦¼ìš©)
                   â””â”€ ì‹¤íŒ¨ â†’ coupon.issue.failed (DLQ)
```

### Kafka í† í”½ ì„¤ê³„

```java
// ì¿ í° ë°œê¸‰ ìš”ì²­ í† í”½
public static final String COUPON_ISSUE_REQUESTED_TOPIC = "coupon.issue.requested";

// ì¿ í° ë°œê¸‰ ì„±ê³µ í† í”½
public static final String COUPON_ISSUED_TOPIC = "coupon.issued";

// ì¿ í° ë°œê¸‰ ì‹¤íŒ¨ í† í”½ (Dead Letter Queue)
public static final String COUPON_ISSUE_FAILED_TOPIC = "coupon.issue.failed";

// ëŒ€ê¸°ì—´ ì§„ì… í† í”½
public static final String QUEUE_ENTERED_TOPIC = "queue.entered";

// ëŒ€ê¸°ì—´ ì²˜ë¦¬ ì™„ë£Œ í† í”½
public static final String QUEUE_PROCESSED_TOPIC = "queue.processed";
```

**í† í”½ ì„¤ì •:**
- **Partitions**: 10ê°œ (ì²˜ë¦¬ëŸ‰ì— ë”°ë¼ ì¡°ì •)
- **Replication Factor**: 3 (í”„ë¡œë•ì…˜ í™˜ê²½)
- **Retention**: 7ì¼ (ì¬ì²˜ë¦¬ ë° ë””ë²„ê¹…ìš©)
- **Cleanup Policy**: delete (ì‹œê°„ ê¸°ë°˜ ì‚­ì œ)

---

## ì¿ í° ë°œê¸‰ ì‹œìŠ¤í…œ

### 1. ì„ ì°©ìˆœ ì¿ í° ë°œê¸‰ íë¦„

#### Phase 1: ìš”ì²­ ì ‘ìˆ˜ (Producer)

```java
@RestController
@RequestMapping("/api/coupons")
public class CouponController {

    private final RedisTemplate<String, String> redisTemplate;
    private final KafkaTemplate<String, CouponIssueRequestedEvent> kafkaTemplate;

    /**
     * ì„ ì°©ìˆœ ì¿ í° ë°œê¸‰ ìš”ì²­
     *
     * Redisë¡œ ë¹ ë¥¸ ì¤‘ë³µ ì²´í¬ â†’ Kafkaë¡œ ë¹„ë™ê¸° ì²˜ë¦¬
     *
     * @return 202 Accepted (ì²˜ë¦¬ ëŒ€ê¸° ì¤‘)
     */
    @PostMapping("/{couponId}/issue")
    public ResponseEntity<CouponIssueResponse> issueCoupon(
            @PathVariable Long couponId,
            @RequestHeader("X-User-Public-Id") String publicId) {

        Long userId = getUserIdByPublicId(publicId);

        // ====================================
        // Step 1: Redis ì¤‘ë³µ ì²´í¬ (ë¹ ë¥¸ ì‹¤íŒ¨)
        // ====================================
        String redisKey = "coupon:issued:" + couponId + ":" + userId;
        Boolean isFirstRequest = redisTemplate.opsForValue()
            .setIfAbsent(redisKey, "1", Duration.ofHours(24));

        if (!isFirstRequest) {
            throw new DuplicateCouponRequestException("ì´ë¯¸ ë°œê¸‰ ìš”ì²­í•œ ì¿ í°ì…ë‹ˆë‹¤");
        }

        // ====================================
        // Step 2: Redis ì¬ê³  í™•ì¸ (ë¹ ë¥¸ ì‹¤íŒ¨)
        // ====================================
        String stockKey = "coupon:stock:" + couponId;
        Long remainingStock = redisTemplate.opsForValue().decrement(stockKey);

        if (remainingStock == null || remainingStock < 0) {
            // Redis ë¡¤ë°±
            redisTemplate.opsForValue().increment(stockKey);
            redisTemplate.delete(redisKey);
            throw new CouponSoldOutException("ì¿ í°ì´ ëª¨ë‘ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤");
        }

        // ====================================
        // Step 3: Kafka ì´ë²¤íŠ¸ ë°œí–‰
        // ====================================
        CouponIssueRequestedEvent event = new CouponIssueRequestedEvent(
            UUID.randomUUID().toString(),  // requestId (ë©±ë“±ì„± í‚¤)
            couponId,
            userId,
            Instant.now()
        );

        // Keyë¥¼ userIdë¡œ ì„¤ì •í•˜ì—¬ ê°™ì€ ì‚¬ìš©ìëŠ” ê°™ì€ íŒŒí‹°ì…˜ìœ¼ë¡œ ì „ì†¡
        // â†’ ìˆœì„œ ë³´ì¥ (í•œ ì‚¬ìš©ìì˜ ìš”ì²­ì€ ìˆœì°¨ ì²˜ë¦¬)
        kafkaTemplate.send(
            KafkaConfig.COUPON_ISSUE_REQUESTED_TOPIC,
            userId.toString(),  // partition key
            event
        );

        log.info("[ì¿ í°] ë°œê¸‰ ìš”ì²­ ì ‘ìˆ˜: couponId={}, userId={}, requestId={}",
            couponId, userId, event.requestId());

        // ====================================
        // Step 4: ì¦‰ì‹œ ì‘ë‹µ (ë¹„ë™ê¸° ì²˜ë¦¬)
        // ====================================
        return ResponseEntity.accepted()
            .body(new CouponIssueResponse(
                event.requestId(),
                "ì¿ í° ë°œê¸‰ ìš”ì²­ì´ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
                remainingStock
            ));
    }
}
```

**í•µì‹¬ ì„¤ê³„ í¬ì¸íŠ¸:**

1. **Redis ì¤‘ë³µ ì²´í¬** (`setIfAbsent`)
   - ë™ì¼ ì‚¬ìš©ìì˜ ì¤‘ë³µ ìš”ì²­ì„ ë¹ ë¥´ê²Œ ì°¨ë‹¨
   - DB ë¶€í•˜ ì—†ì´ ë©”ëª¨ë¦¬ì—ì„œ ì¦‰ì‹œ ì²˜ë¦¬

2. **Redis ì¬ê³  í™•ì¸** (`decrement`)
   - Atomic ì—°ì‚°ìœ¼ë¡œ ë™ì‹œì„± ì œì–´
   - ì¿ í° ì†Œì§„ ì‹œ ë¹ ë¥¸ ì‹¤íŒ¨ ì‘ë‹µ

3. **Kafka Key ì „ëµ** (userId)
   - ê°™ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì€ ê°™ì€ íŒŒí‹°ì…˜ìœ¼ë¡œ ì „ì†¡
   - ìˆœì„œ ë³´ì¥ ë° ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€

4. **ë¹„ë™ê¸° ì‘ë‹µ** (202 Accepted)
   - API ì‘ë‹µ ì†ë„ í–¥ìƒ (200ms ì´ë‚´)
   - ì‹¤ì œ ë°œê¸‰ì€ Consumerê°€ ì²˜ë¦¬

---

#### Phase 2: ì¿ í° ë°œê¸‰ ì²˜ë¦¬ (Consumer)

```java
@Component
@Slf4j
public class CouponIssueEventHandler {

    private final CouponService couponService;
    private final UserService userService;
    private final RedisTemplate<String, String> redisTemplate;
    private final KafkaTemplate<String, Object> kafkaTemplate;

    /**
     * ì¿ í° ë°œê¸‰ ìš”ì²­ ì²˜ë¦¬
     *
     * Kafka Consumerê°€ ìš”ì²­ì„ êº¼ë‚´ì„œ ì‹¤ì œ DBì— ë°œê¸‰
     *
     * Consumer Group: coupon-issue-service
     * Concurrency: 10 (íŒŒí‹°ì…˜ ìˆ˜ì™€ ë™ì¼)
     */
    @Transactional
    @KafkaListener(
        topics = KafkaConfig.COUPON_ISSUE_REQUESTED_TOPIC,
        groupId = "coupon-issue-service",
        concurrency = "10"  // 10ê°œ Consumer ìŠ¤ë ˆë“œ (íŒŒí‹°ì…˜ ìˆ˜ì™€ ë™ì¼)
    )
    public void handleCouponIssueRequested(CouponIssueRequestedEvent event) {
        try {
            log.info("[ì¿ í°-Kafka] ë°œê¸‰ ì²˜ë¦¬ ì‹œì‘: requestId={}, couponId={}, userId={}",
                event.requestId(), event.couponId(), event.userId());

            // ====================================
            // Step 1: ë©±ë“±ì„± ì²´í¬ (ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€)
            // ====================================
            String idempotencyKey = "coupon:processed:" + event.requestId();
            Boolean isFirstProcessing = redisTemplate.opsForValue()
                .setIfAbsent(idempotencyKey, "1", Duration.ofDays(7));

            if (!isFirstProcessing) {
                log.warn("[ì¿ í°-Kafka] ì¤‘ë³µ ì²˜ë¦¬ ìš”ì²­ ë¬´ì‹œ: requestId={}", event.requestId());
                return;  // ì´ë¯¸ ì²˜ë¦¬ë¨
            }

            // ====================================
            // Step 2: DBì—ì„œ ì‹¤ì œ ë°œê¸‰
            // ====================================
            Coupon coupon = couponService.getCouponWithLock(event.couponId());
            User user = userService.getUser(event.userId());

            // ì¬ê³  í™•ì¸ (ë¹„ê´€ì  ë½)
            if (!coupon.hasStock()) {
                throw new CouponSoldOutException("ì¿ í° ì¬ê³ ê°€ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤");
            }

            // ì¤‘ë³µ ë°œê¸‰ ì²´í¬ (DB unique ì œì•½)
            UserCoupon userCoupon = couponService.issueCoupon(coupon, user);

            log.info("[ì¿ í°-Kafka] ë°œê¸‰ ì™„ë£Œ: userCouponId={}, couponId={}, userId={}",
                userCoupon.getId(), event.couponId(), event.userId());

            // ====================================
            // Step 3: ì„±ê³µ ì´ë²¤íŠ¸ ë°œí–‰
            // ====================================
            CouponIssuedEvent successEvent = new CouponIssuedEvent(
                event.requestId(),
                userCoupon.getId(),
                event.couponId(),
                event.userId(),
                Instant.now()
            );

            kafkaTemplate.send(
                KafkaConfig.COUPON_ISSUED_TOPIC,
                event.userId().toString(),
                successEvent
            );

            // ====================================
            // Step 4: Redis ìºì‹œ ì—…ë°ì´íŠ¸
            // ====================================
            updateRedisCacheAfterIssue(event.couponId(), event.userId());

        } catch (CouponSoldOutException | DuplicateCouponException e) {
            // ì˜ˆìƒëœ ì‹¤íŒ¨ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
            log.warn("[ì¿ í°-Kafka] ë°œê¸‰ ì‹¤íŒ¨ (ì˜ˆìƒ): requestId={}, reason={}",
                event.requestId(), e.getMessage());

            publishFailureEvent(event, e.getMessage());
            rollbackRedisCache(event);

        } catch (Exception e) {
            // ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜
            log.error("[ì¿ í°-Kafka] ë°œê¸‰ ì‹¤íŒ¨ (ì‹œìŠ¤í…œ ì˜¤ë¥˜): requestId={}, error={}",
                event.requestId(), e.getMessage(), e);

            publishFailureEvent(event, "ì‹œìŠ¤í…œ ì˜¤ë¥˜: " + e.getMessage());
            rollbackRedisCache(event);

            // ì¬ì‹œë„ë¥¼ ìœ„í•´ ì˜ˆì™¸ë¥¼ ë˜ì§€ì§€ ì•ŠìŒ (DLQë¡œ ì „ì†¡ë¨)
        }
    }

    /**
     * ì‹¤íŒ¨ ì´ë²¤íŠ¸ ë°œí–‰ (DLQ)
     */
    private void publishFailureEvent(CouponIssueRequestedEvent event, String reason) {
        CouponIssueFailedEvent failEvent = new CouponIssueFailedEvent(
            event.requestId(),
            event.couponId(),
            event.userId(),
            reason,
            Instant.now()
        );

        kafkaTemplate.send(
            KafkaConfig.COUPON_ISSUE_FAILED_TOPIC,
            event.userId().toString(),
            failEvent
        );
    }

    /**
     * Redis ìºì‹œ ë¡¤ë°± (ì¬ê³  ë³µêµ¬)
     */
    private void rollbackRedisCache(CouponIssueRequestedEvent event) {
        String stockKey = "coupon:stock:" + event.couponId();
        redisTemplate.opsForValue().increment(stockKey);

        String userKey = "coupon:issued:" + event.couponId() + ":" + event.userId();
        redisTemplate.delete(userKey);
    }
}
```

**í•µì‹¬ ì„¤ê³„ í¬ì¸íŠ¸:**

1. **ë©±ë“±ì„± ë³´ì¥** (Idempotency)
   - requestIdë¥¼ í‚¤ë¡œ Redisì— ì²˜ë¦¬ ì—¬ë¶€ ì €ì¥
   - Kafkaì˜ "ìµœì†Œ 1íšŒ ì „ë‹¬"ë¡œ ì¸í•œ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€

2. **ë¹„ê´€ì  ë½** (Pessimistic Lock)
   - DBì—ì„œ ì‹¤ì œ ì¬ê³ ë¥¼ í™•ì¸í•  ë•Œ SELECT FOR UPDATE
   - ë™ì‹œì„± ì œì–´ì˜ ìµœì¢… ë°©ì–´ì„ 

3. **Consumer Concurrency**
   - íŒŒí‹°ì…˜ ìˆ˜(10ê°œ)ì™€ ë™ì¼í•œ Consumer ìŠ¤ë ˆë“œ ì‹¤í–‰
   - ì²˜ë¦¬ëŸ‰ ê·¹ëŒ€í™”

4. **ì‹¤íŒ¨ ì²˜ë¦¬**
   - ë¹„ì¦ˆë‹ˆìŠ¤ ì‹¤íŒ¨: DLQë¡œ ì „ì†¡
   - ì‹œìŠ¤í…œ ì˜¤ë¥˜: ì¬ì‹œë„ (Kafka ì„¤ì •)

---

### 2. Kafka íŠ¹ì§• í™œìš©

#### 2-1. ìˆœì„œ ë³´ì¥ (Ordering)

**ë¬¸ì œ:**
- ê°™ì€ ì‚¬ìš©ìê°€ ë¹ ë¥´ê²Œ ì—¬ëŸ¬ ìš”ì²­ì„ ë³´ë‚¼ ê²½ìš° ìˆœì„œê°€ ë’¤ë°”ë€” ìˆ˜ ìˆìŒ

**í•´ê²°:**
```java
// ê°™ì€ userIdëŠ” ê°™ì€ íŒŒí‹°ì…˜ìœ¼ë¡œ ì „ì†¡
kafkaTemplate.send(
    KafkaConfig.COUPON_ISSUE_REQUESTED_TOPIC,
    userId.toString(),  // partition key
    event
);
```
- KafkaëŠ” ê°™ì€ Keyì˜ ë©”ì‹œì§€ë¥¼ ê°™ì€ íŒŒí‹°ì…˜ì— ìˆœì°¨ì ìœ¼ë¡œ ì €ì¥
- ConsumerëŠ” íŒŒí‹°ì…˜ ë‚´ì—ì„œ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬

#### 2-2. ì˜ì†ì„± (Durability)

**ë¬¸ì œ:**
- Consumer ì¥ì•  ì‹œ ë©”ì‹œì§€ ìœ ì‹¤ ê°€ëŠ¥ì„±

**í•´ê²°:**
```yaml
# Kafka Producer ì„¤ì •
spring:
  kafka:
    producer:
      acks: all  # ëª¨ë“  replicaê°€ ìˆ˜ì‹  í™•ì¸í•  ë•Œê¹Œì§€ ëŒ€ê¸°
      retries: 3
      properties:
        enable.idempotence: true  # ë©±ë“±ì„± ë³´ì¥ (ì¤‘ë³µ ë°©ì§€)
```
- ë©”ì‹œì§€ë¥¼ ë””ìŠ¤í¬ì— ì˜ì†í™”
- Replication Factor 3ìœ¼ë¡œ ë°ì´í„° ë³µì œ
- Consumer ì¥ì•  ë³µêµ¬ ì‹œ ë§ˆì§€ë§‰ Offsetë¶€í„° ì¬ì²˜ë¦¬

#### 2-3. ì¬ì²˜ë¦¬ (Replay)

**ë¬¸ì œ:**
- ì¿ í° ë°œê¸‰ ì¤‘ ë²„ê·¸ ë°œê²¬ ì‹œ íŠ¹ì • ì‹œì ë¶€í„° ì¬ì²˜ë¦¬ í•„ìš”

**í•´ê²°:**
```bash
# Consumer Group Offset ë¦¬ì…‹
kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --group coupon-issue-service \
  --topic coupon.issue.requested \
  --reset-offsets --to-datetime 2025-12-18T10:00:00.000 \
  --execute
```
- KafkaëŠ” ë©”ì‹œì§€ë¥¼ 7ì¼ê°„ ë³´ê´€
- íŠ¹ì • ì‹œì ë¶€í„° ì¬ì²˜ë¦¬ ê°€ëŠ¥
- ìš´ì˜ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ ë³µêµ¬ì— ìœ ìš©

#### 2-4. ë†’ì€ ì²˜ë¦¬ëŸ‰ (High Throughput)

**íŒŒí‹°ì…”ë‹ ì „ëµ:**
```java
@Bean
public NewTopic couponIssueRequestedTopic() {
    return TopicBuilder.name(COUPON_ISSUE_REQUESTED_TOPIC)
            .partitions(10)  // 10ê°œ íŒŒí‹°ì…˜
            .replicas(3)     // ë³µì œë³¸ 3ê°œ
            .config("compression.type", "lz4")  // ì••ì¶•
            .build();
}
```
- 10ê°œ íŒŒí‹°ì…˜ Ã— 10ê°œ Consumer = ë³‘ë ¬ ì²˜ë¦¬
- ì´ˆë‹¹ 10ë§Œ ìš”ì²­ ì²˜ë¦¬ ê°€ëŠ¥

---

## ëŒ€ê¸°ì—´ ì‹œìŠ¤í…œ

### 1. ëŒ€ê¸°ì—´ ì§„ì… íë¦„

```
ì‚¬ìš©ì ìš”ì²­ (10ë§Œ/ì´ˆ)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Gateway     â”‚ â† Rate Limiting (ì‚¬ìš©ìë‹¹ 1 req/sec)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Queue Controllerâ”‚
â”‚ 1. Redis ëŒ€ê¸°ë²ˆí˜¸â”‚ â† INCR (Atomic)
â”‚ 2. Kafka ë°œí–‰   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Topic: queue.entered
         â”‚ Key: queueId (ëŒ€ê¸°ì—´ë³„ ë¶„ë¦¬)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kafka Broker    â”‚
â”‚ (100ë§Œ ë©”ì‹œì§€)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Consumer: queue-processor-service
         â”‚ Concurrency: 20
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Queue Processor  â”‚
â”‚ 1. ìˆœì°¨ ì²˜ë¦¬    â”‚ â† íŒŒí‹°ì…˜ ë‚´ ìˆœì„œ ë³´ì¥
â”‚ 2. ì‹¤ì œ ì‘ì—… ì‹¤í–‰â”‚
â”‚ 3. ì™„ë£Œ ì´ë²¤íŠ¸  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. ëŒ€ê¸°ì—´ ì§„ì… API

```java
@RestController
@RequestMapping("/api/queue")
public class QueueController {

    private final RedisTemplate<String, String> redisTemplate;
    private final KafkaTemplate<String, QueueEnteredEvent> kafkaTemplate;

    /**
     * ëŒ€ê¸°ì—´ ì§„ì…
     *
     * Redis Atomic Counterë¡œ ëŒ€ê¸° ë²ˆí˜¸ ë°œê¸‰ â†’ Kafkaë¡œ ìˆœì°¨ ì²˜ë¦¬
     */
    @PostMapping("/{queueId}/enter")
    public ResponseEntity<QueueEntryResponse> enterQueue(
            @PathVariable String queueId,
            @RequestHeader("X-User-Public-Id") String publicId) {

        Long userId = getUserIdByPublicId(publicId);

        // ====================================
        // Step 1: Redisë¡œ ëŒ€ê¸° ë²ˆí˜¸ ë°œê¸‰
        // ====================================
        String counterKey = "queue:counter:" + queueId;
        Long queueNumber = redisTemplate.opsForValue().increment(counterKey);

        // ====================================
        // Step 2: Redisì— ì‚¬ìš©ì ì •ë³´ ì €ì¥
        // ====================================
        String userKey = "queue:user:" + queueId + ":" + userId;
        QueueUserInfo userInfo = new QueueUserInfo(
            userId,
            queueNumber,
            QueueStatus.WAITING,
            Instant.now()
        );
        redisTemplate.opsForValue().set(
            userKey,
            objectMapper.writeValueAsString(userInfo),
            Duration.ofHours(1)
        );

        // ====================================
        // Step 3: Kafka ì´ë²¤íŠ¸ ë°œí–‰
        // ====================================
        QueueEnteredEvent event = new QueueEnteredEvent(
            queueId,
            userId,
            queueNumber,
            Instant.now()
        );

        // Keyë¥¼ queueIdë¡œ ì„¤ì •í•˜ì—¬ ê°™ì€ ëŒ€ê¸°ì—´ì€ ê°™ì€ íŒŒí‹°ì…˜ìœ¼ë¡œ
        kafkaTemplate.send(
            KafkaConfig.QUEUE_ENTERED_TOPIC,
            queueId,  // partition key
            event
        );

        log.info("[ëŒ€ê¸°ì—´] ì§„ì…: queueId={}, userId={}, queueNumber={}",
            queueId, userId, queueNumber);

        // ====================================
        // Step 4: ì˜ˆìƒ ëŒ€ê¸° ì‹œê°„ ê³„ì‚°
        // ====================================
        Long processingRate = getProcessingRate(queueId);  // ì´ˆë‹¹ ì²˜ë¦¬ ê±´ìˆ˜
        long estimatedWaitSeconds = (queueNumber - getCurrentProcessingNumber(queueId))
            / processingRate;

        return ResponseEntity.ok(new QueueEntryResponse(
            queueNumber,
            queueNumber - getCurrentProcessingNumber(queueId),  // ë‚´ ì•ì— ëŒ€ê¸°ì ìˆ˜
            estimatedWaitSeconds,
            "ëŒ€ê¸°ì—´ì— ì§„ì…í–ˆìŠµë‹ˆë‹¤"
        ));
    }

    /**
     * ë‚´ ëŒ€ê¸° ìƒíƒœ ì¡°íšŒ
     */
    @GetMapping("/{queueId}/status")
    public ResponseEntity<QueueStatusResponse> getQueueStatus(
            @PathVariable String queueId,
            @RequestHeader("X-User-Public-Id") String publicId) {

        Long userId = getUserIdByPublicId(publicId);

        String userKey = "queue:user:" + queueId + ":" + userId;
        String userInfoJson = redisTemplate.opsForValue().get(userKey);

        if (userInfoJson == null) {
            throw new QueueEntryNotFoundException("ëŒ€ê¸°ì—´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤");
        }

        QueueUserInfo userInfo = objectMapper.readValue(userInfoJson, QueueUserInfo.class);
        Long currentNumber = getCurrentProcessingNumber(queueId);

        return ResponseEntity.ok(new QueueStatusResponse(
            userInfo.queueNumber(),
            userInfo.queueNumber() - currentNumber,  // ë‚´ ì•ì— ëŒ€ê¸°ì ìˆ˜
            userInfo.status(),
            calculateEstimatedTime(queueId, userInfo.queueNumber(), currentNumber)
        ));
    }
}
```

### 3. ëŒ€ê¸°ì—´ ì²˜ë¦¬ Consumer

```java
@Component
@Slf4j
public class QueueProcessorEventHandler {

    private final RedisTemplate<String, String> redisTemplate;
    private final KafkaTemplate<String, Object> kafkaTemplate;

    /**
     * ëŒ€ê¸°ì—´ ìˆœì°¨ ì²˜ë¦¬
     *
     * Consumer Group: queue-processor-service
     * Concurrency: 20 (íŒŒí‹°ì…˜ ìˆ˜)
     *
     * Kafkaì˜ ìˆœì„œ ë³´ì¥ íŠ¹ì„±ì„ í™œìš©í•˜ì—¬ FIFO ì²˜ë¦¬
     */
    @KafkaListener(
        topics = KafkaConfig.QUEUE_ENTERED_TOPIC,
        groupId = "queue-processor-service",
        concurrency = "20"
    )
    public void processQueue(QueueEnteredEvent event) {
        try {
            log.info("[ëŒ€ê¸°ì—´-Kafka] ì²˜ë¦¬ ì‹œì‘: queueId={}, userId={}, queueNumber={}",
                event.queueId(), event.userId(), event.queueNumber());

            // ====================================
            // Step 1: Rate Limiting (ì²˜ë¦¬ ì†ë„ ì œì–´)
            // ====================================
            // ì˜ˆ: ì´ˆë‹¹ 1000ê±´ ì²˜ë¦¬ë¥¼ ëª©í‘œë¡œ í•  ê²½ìš°
            rateLimiter.acquire();  // Guava RateLimiter

            // ====================================
            // Step 2: ì‚¬ìš©ì ìƒíƒœ ì—…ë°ì´íŠ¸ (ì²˜ë¦¬ ì¤‘)
            // ====================================
            updateUserStatus(event.queueId(), event.userId(), QueueStatus.PROCESSING);

            // ====================================
            // Step 3: ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì‹¤í–‰
            // ====================================
            // ì˜ˆ: í‹°ì¼“ ì˜ˆë§¤, ì¿ í° ë°œê¸‰, ì£¼ë¬¸ ì²˜ë¦¬ ë“±
            executeBusinessLogic(event);

            // ====================================
            // Step 4: ì²˜ë¦¬ ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
            // ====================================
            updateUserStatus(event.queueId(), event.userId(), QueueStatus.COMPLETED);

            // í˜„ì¬ ì²˜ë¦¬ ë²ˆí˜¸ ì—…ë°ì´íŠ¸
            updateCurrentProcessingNumber(event.queueId(), event.queueNumber());

            log.info("[ëŒ€ê¸°ì—´-Kafka] ì²˜ë¦¬ ì™„ë£Œ: queueId={}, userId={}, queueNumber={}",
                event.queueId(), event.userId(), event.queueNumber());

            // ====================================
            // Step 5: ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰ (ì•Œë¦¼ìš©)
            // ====================================
            QueueProcessedEvent completedEvent = new QueueProcessedEvent(
                event.queueId(),
                event.userId(),
                event.queueNumber(),
                Instant.now()
            );

            kafkaTemplate.send(
                KafkaConfig.QUEUE_PROCESSED_TOPIC,
                event.userId().toString(),
                completedEvent
            );

        } catch (Exception e) {
            log.error("[ëŒ€ê¸°ì—´-Kafka] ì²˜ë¦¬ ì‹¤íŒ¨: queueId={}, userId={}, error={}",
                event.queueId(), event.userId(), e.getMessage(), e);

            updateUserStatus(event.queueId(), event.userId(), QueueStatus.FAILED);

            // ì¬ì‹œë„ ë˜ëŠ” DLQë¡œ ì „ì†¡
            throw e;
        }
    }

    /**
     * ì‚¬ìš©ì ìƒíƒœ ì—…ë°ì´íŠ¸ (Redis)
     */
    private void updateUserStatus(String queueId, Long userId, QueueStatus status) {
        String userKey = "queue:user:" + queueId + ":" + userId;
        String userInfoJson = redisTemplate.opsForValue().get(userKey);

        if (userInfoJson != null) {
            QueueUserInfo userInfo = objectMapper.readValue(userInfoJson, QueueUserInfo.class);
            QueueUserInfo updated = new QueueUserInfo(
                userInfo.userId(),
                userInfo.queueNumber(),
                status,
                userInfo.enteredAt()
            );

            redisTemplate.opsForValue().set(
                userKey,
                objectMapper.writeValueAsString(updated),
                Duration.ofHours(1)
            );
        }
    }

    /**
     * í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ëŒ€ê¸° ë²ˆí˜¸ ì—…ë°ì´íŠ¸
     */
    private void updateCurrentProcessingNumber(String queueId, Long queueNumber) {
        String currentKey = "queue:current:" + queueId;
        redisTemplate.opsForValue().set(currentKey, queueNumber.toString());
    }
}
```

---

## Kafka íŠ¹ì§• í™œìš© ì „ëµ

### 1. íŒŒí‹°ì…”ë‹ ì „ëµ

#### ì¿ í° ë°œê¸‰: userId ê¸°ë°˜ íŒŒí‹°ì…”ë‹
```java
// ê°™ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì€ ê°™ì€ íŒŒí‹°ì…˜ìœ¼ë¡œ
kafkaTemplate.send(topic, userId.toString(), event);
```
**ì¥ì :**
- í•œ ì‚¬ìš©ìì˜ ì—¬ëŸ¬ ìš”ì²­ì´ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬ë¨
- ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€ì— ìœ ë¦¬

#### ëŒ€ê¸°ì—´: queueId ê¸°ë°˜ íŒŒí‹°ì…”ë‹
```java
// ê°™ì€ ëŒ€ê¸°ì—´ì˜ ìš”ì²­ì€ ê°™ì€ íŒŒí‹°ì…˜ìœ¼ë¡œ
kafkaTemplate.send(topic, queueId, event);
```
**ì¥ì :**
- ëŒ€ê¸°ì—´ë³„ë¡œ ë…ë¦½ì ì¸ ì²˜ë¦¬
- FIFO ìˆœì„œ ë³´ì¥

### 2. Consumer Group ì „ëµ

```yaml
# application.yml
spring:
  kafka:
    consumer:
      group-id: coupon-issue-service
      enable-auto-commit: false  # ìˆ˜ë™ ì»¤ë°‹ (íŠ¸ëœì­ì…˜ ì™„ë£Œ í›„)
      auto-offset-reset: earliest  # ì²˜ìŒë¶€í„° ì½ê¸° (ì¥ì•  ë³µêµ¬)
      max-poll-records: 500  # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë©”ì‹œì§€ ìˆ˜
    listener:
      ack-mode: manual  # ìˆ˜ë™ ACK (ì²˜ë¦¬ ì™„ë£Œ í›„)
      concurrency: 10  # Consumer ìŠ¤ë ˆë“œ ìˆ˜
```

**Consumer ìˆ˜í‰ í™•ì¥:**
```
íŒŒí‹°ì…˜ 10ê°œ â†’ Consumer ì¸ìŠ¤í„´ìŠ¤ 10ê°œ
ê° ì¸ìŠ¤í„´ìŠ¤ê°€ 1ê°œ íŒŒí‹°ì…˜ ë‹´ë‹¹
â†’ 10ë°° ì²˜ë¦¬ëŸ‰ ì¦ê°€
```

### 3. ë©”ì‹œì§€ ì••ì¶•

```java
@Bean
public ProducerFactory<String, Object> producerFactory() {
    Map<String, Object> props = new HashMap<>();
    props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "lz4");  // lz4 ì••ì¶•
    props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);  // ë°°ì¹˜ í¬ê¸°
    props.put(ProducerConfig.LINGER_MS_CONFIG, 10);  // ë°°ì¹˜ ëŒ€ê¸° ì‹œê°„
    return new DefaultKafkaProducerFactory<>(props);
}
```

**íš¨ê³¼:**
- ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ì ˆì•½ (50% ì´ìƒ)
- ë””ìŠ¤í¬ ì €ì¥ ê³µê°„ ì ˆì•½
- ì²˜ë¦¬ëŸ‰ ì¦ê°€

### 4. Dead Letter Queue (DLQ)

```java
@Configuration
public class KafkaErrorHandlingConfig {

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory =
            new ConcurrentKafkaListenerContainerFactory<>();

        // ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì„¤ì •
        factory.setCommonErrorHandler(new DefaultErrorHandler(
            new DeadLetterPublishingRecoverer(kafkaTemplate(),
                (record, ex) -> {
                    // ì¬ì‹œë„ 3ë²ˆ í›„ DLQë¡œ ì „ì†¡
                    return new TopicPartition(
                        record.topic() + ".failed",  // DLQ í† í”½
                        record.partition()
                    );
                }),
            new FixedBackOff(1000L, 3)  // 1ì´ˆ ê°„ê²©ìœ¼ë¡œ 3ë²ˆ ì¬ì‹œë„
        ));

        return factory;
    }
}
```

**DLQ ì²˜ë¦¬ íë¦„:**
```
1. Consumer ì²˜ë¦¬ ì‹¤íŒ¨
2. 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ (1ë²ˆì§¸)
3. 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ (2ë²ˆì§¸)
4. 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ (3ë²ˆì§¸)
5. ì—¬ì „íˆ ì‹¤íŒ¨ â†’ DLQ (coupon.issue.requested.failed)ë¡œ ì „ì†¡
6. ìš´ì˜ìê°€ ìˆ˜ë™ìœ¼ë¡œ í™•ì¸ ë° ì²˜ë¦¬
```

---

## ì¥ì•  ì²˜ë¦¬ ë° ëª¨ë‹ˆí„°ë§

### 1. ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ ë° ëŒ€ì‘

#### ì‹œë‚˜ë¦¬ì˜¤ 1: Consumer ì¥ì• 
**ë¬¸ì œ:**
- Consumer ì¸ìŠ¤í„´ìŠ¤ ë‹¤ìš´
- ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ë‹¨

**ëŒ€ì‘:**
```
1. KafkaëŠ” ë©”ì‹œì§€ë¥¼ ë³´ê´€ (Retention: 7ì¼)
2. Consumer Groupì˜ ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤ê°€ íŒŒí‹°ì…˜ ì¸ê³„ (Rebalancing)
3. ë˜ëŠ” ìƒˆ Consumer ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘ ì‹œ ë§ˆì§€ë§‰ Offsetë¶€í„° ì¬ê°œ
```

**ëª¨ë‹ˆí„°ë§:**
```java
// Consumer Lag ëª¨ë‹ˆí„°ë§ (Micrometer)
@Component
public class KafkaConsumerMetrics {

    @Scheduled(fixedRate = 10000)  // 10ì´ˆë§ˆë‹¤
    public void recordConsumerLag() {
        AdminClient adminClient = AdminClient.create(kafkaConfig);

        Map<TopicPartition, OffsetAndMetadata> offsets =
            adminClient.listConsumerGroupOffsets("coupon-issue-service")
                .partitionsToOffsetAndMetadata().get();

        for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {
            long lag = calculateLag(entry.getKey(), entry.getValue());

            Metrics.gauge("kafka.consumer.lag",
                Tags.of("topic", entry.getKey().topic(),
                        "partition", String.valueOf(entry.getKey().partition())),
                lag);

            // Lagì´ 10000 ì´ìƒì´ë©´ ì•ŒëŒ
            if (lag > 10000) {
                alertService.sendAlert("Kafka Consumer Lag ë†’ìŒ: " + lag);
            }
        }
    }
}
```

#### ì‹œë‚˜ë¦¬ì˜¤ 2: Kafka Broker ì¥ì• 
**ë¬¸ì œ:**
- Broker ë‹¤ìš´
- ë©”ì‹œì§€ ìœ ì‹¤ ìœ„í—˜

**ëŒ€ì‘:**
```
1. Replication Factor 3ìœ¼ë¡œ ì„¤ì •
2. Leader Broker ì¥ì•  ì‹œ ìë™ìœ¼ë¡œ Followerê°€ Leaderë¡œ ìŠ¹ê²©
3. ë©”ì‹œì§€ ìœ ì‹¤ ì—†ìŒ (acks=all ì„¤ì •)
```

#### ì‹œë‚˜ë¦¬ì˜¤ 3: ë„¤íŠ¸ì›Œí¬ íŒŒí‹°ì…˜
**ë¬¸ì œ:**
- Producerì™€ Kafka ì—°ê²° ëŠê¹€

**ëŒ€ì‘:**
```java
// Producer ì¬ì‹œë„ ì„¤ì •
spring:
  kafka:
    producer:
      retries: 2147483647  # ë¬´í•œ ì¬ì‹œë„
      max-in-flight-requests-per-connection: 1  # ìˆœì„œ ë³´ì¥
      properties:
        retry.backoff.ms: 1000  # 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
```

### 2. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

#### Grafana + Prometheus ë©”íŠ¸ë¦­

```yaml
# ì£¼ìš” ëª¨ë‹ˆí„°ë§ ì§€í‘œ

1. Producer ë©”íŠ¸ë¦­:
   - kafka_producer_record_send_total: ë°œí–‰í•œ ë©”ì‹œì§€ ìˆ˜
   - kafka_producer_record_error_total: ë°œí–‰ ì‹¤íŒ¨ ìˆ˜
   - kafka_producer_request_latency_avg: í‰ê·  ë ˆì´í„´ì‹œ

2. Consumer ë©”íŠ¸ë¦­:
   - kafka_consumer_records_consumed_total: ì†Œë¹„í•œ ë©”ì‹œì§€ ìˆ˜
   - kafka_consumer_lag: Consumer Lag (ì²˜ë¦¬ ì§€ì—°)
   - kafka_consumer_fetch_manager_records_lag_max: ìµœëŒ€ Lag

3. ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­:
   - coupon_issued_total: ë°œê¸‰ëœ ì¿ í° ìˆ˜
   - coupon_issue_failed_total: ì‹¤íŒ¨í•œ ë°œê¸‰ ìˆ˜
   - queue_processing_time: ëŒ€ê¸°ì—´ ì²˜ë¦¬ ì‹œê°„
   - queue_wait_count: ëŒ€ê¸° ì¤‘ì¸ ì‚¬ìš©ì ìˆ˜
```

#### ì•ŒëŒ ì„¤ì •

```yaml
# Prometheus Alert Rules

groups:
  - name: kafka_alerts
    rules:
      # Consumer Lag ì•ŒëŒ
      - alert: HighConsumerLag
        expr: kafka_consumer_lag > 10000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Kafka Consumer Lag ë†’ìŒ"
          description: "Consumer Lagì´ 10000 ì´ìƒì…ë‹ˆë‹¤. ì²˜ë¦¬ ì†ë„ë¥¼ í™•ì¸í•˜ì„¸ìš”."

      # ì¿ í° ë°œê¸‰ ì‹¤íŒ¨ìœ¨ ì•ŒëŒ
      - alert: HighCouponIssueFailureRate
        expr: rate(coupon_issue_failed_total[5m]) > 0.1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "ì¿ í° ë°œê¸‰ ì‹¤íŒ¨ìœ¨ ë†’ìŒ"
          description: "ì¿ í° ë°œê¸‰ ì‹¤íŒ¨ìœ¨ì´ 10% ì´ìƒì…ë‹ˆë‹¤."

      # Broker ë‹¤ìš´ ì•ŒëŒ
      - alert: KafkaBrokerDown
        expr: kafka_server_broker_state == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Kafka Broker ë‹¤ìš´"
          description: "Kafka Brokerê°€ ë‹¤ìš´ë˜ì—ˆìŠµë‹ˆë‹¤."
```

---

## ì„±ëŠ¥ ìµœì í™”

### 1. ì²˜ë¦¬ëŸ‰ ìµœì í™”

#### Producer ë°°ì¹˜ ì²˜ë¦¬
```java
@Bean
public ProducerFactory<String, Object> producerFactory() {
    Map<String, Object> props = new HashMap<>();

    // ë°°ì¹˜ ì„¤ì •
    props.put(ProducerConfig.BATCH_SIZE_CONFIG, 32768);  // 32KB ë°°ì¹˜
    props.put(ProducerConfig.LINGER_MS_CONFIG, 10);  // 10ms ëŒ€ê¸° (ë°°ì¹˜ ì¶•ì )
    props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);  // 32MB ë²„í¼

    // ì••ì¶•
    props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "lz4");

    // ë©±ë“±ì„± (ì¤‘ë³µ ë°©ì§€)
    props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
    props.put(ProducerConfig.ACKS_CONFIG, "all");

    return new DefaultKafkaProducerFactory<>(props);
}
```

**íš¨ê³¼:**
- ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë„¤íŠ¸ì›Œí¬ ì™•ë³µ íšŸìˆ˜ ê°ì†Œ
- ì••ì¶•ìœ¼ë¡œ ì „ì†¡ ë°ì´í„°ëŸ‰ ê°ì†Œ
- ì´ˆë‹¹ 10ë§Œ ë©”ì‹œì§€ ì²˜ë¦¬ ê°€ëŠ¥

#### Consumer ë©€í‹°ìŠ¤ë ˆë“œ ì²˜ë¦¬
```yaml
spring:
  kafka:
    listener:
      concurrency: 10  # íŒŒí‹°ì…˜ ìˆ˜ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
      poll-timeout: 3000  # 3ì´ˆ
      type: batch  # ë°°ì¹˜ ì²˜ë¦¬ (ì„±ëŠ¥ í–¥ìƒ)
```

```java
@KafkaListener(
    topics = KafkaConfig.COUPON_ISSUE_REQUESTED_TOPIC,
    groupId = "coupon-issue-service",
    concurrency = "10",
    containerFactory = "batchKafkaListenerContainerFactory"
)
public void handleBatch(List<CouponIssueRequestedEvent> events) {
    // ë°°ì¹˜ë¡œ í•œ ë²ˆì— ì—¬ëŸ¬ ë©”ì‹œì§€ ì²˜ë¦¬
    log.info("[ì¿ í°-Kafka] ë°°ì¹˜ ì²˜ë¦¬: {} ê±´", events.size());

    for (CouponIssueRequestedEvent event : events) {
        processSingleEvent(event);
    }
}
```

### 2. ë ˆì´í„´ì‹œ ìµœì í™”

#### Redis ìºì‹± ì „ëµ
```java
/**
 * ì¿ í° ì¬ê³  ìºì‹± (Read-Through Cache)
 */
@Cacheable(value = "coupon:stock", key = "#couponId")
public Long getCouponStock(Long couponId) {
    return couponRepository.findById(couponId)
        .map(Coupon::getRemainingStock)
        .orElse(0L);
}

/**
 * ì¿ í° ë°œê¸‰ í›„ ìºì‹œ ë¬´íš¨í™”
 */
@CacheEvict(value = "coupon:stock", key = "#couponId")
public void invalidateCouponStockCache(Long couponId) {
    // ìºì‹œ ë¬´íš¨í™”
}
```

#### ë¹„ë™ê¸° ì‘ë‹µ (Non-Blocking)
```java
// Controllerì—ì„œ ì¦‰ì‹œ ì‘ë‹µ (202 Accepted)
return ResponseEntity.accepted()
    .body(new CouponIssueResponse(
        requestId,
        "ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
        estimatedWaitTime
    ));

// ì‹¤ì œ ì²˜ë¦¬ëŠ” Kafka Consumerê°€ ë¹„ë™ê¸°ë¡œ ìˆ˜í–‰
// ì‚¬ìš©ìëŠ” Polling ë˜ëŠ” WebSocketìœ¼ë¡œ ê²°ê³¼ í™•ì¸
```

### 3. ë¹„ìš© ìµœì í™”

#### ë©”ì‹œì§€ ë³´ê´€ ê¸°ê°„ ì„¤ì •
```java
@Bean
public NewTopic couponIssueRequestedTopic() {
    return TopicBuilder.name(COUPON_ISSUE_REQUESTED_TOPIC)
            .partitions(10)
            .replicas(3)
            .config("retention.ms", "604800000")  // 7ì¼ ë³´ê´€
            .config("cleanup.policy", "delete")  // ì‹œê°„ ê¸°ë°˜ ì‚­ì œ
            .build();
}
```

#### Compact Topic (ìƒíƒœ ì €ì¥ìš©)
```java
// ì‚¬ìš©ìë³„ ìµœì‹  ì¿ í° ë°œê¸‰ ìƒíƒœë§Œ ë³´ê´€
@Bean
public NewTopic userCouponStateTopic() {
    return TopicBuilder.name("user.coupon.state")
            .partitions(10)
            .replicas(3)
            .config("cleanup.policy", "compact")  // Keyë³„ ìµœì‹  ë©”ì‹œì§€ë§Œ ë³´ê´€
            .config("min.compaction.lag.ms", "60000")  // 1ë¶„ í›„ Compaction
            .build();
}
```

---

## ê²°ë¡ 

### Kafka ë„ì… íš¨ê³¼

| í•­ëª© | ê¸°ì¡´ (ë™ê¸°) | Kafka ë„ì… í›„ |
|------|-------------|---------------|
| **ì²˜ë¦¬ëŸ‰** | 1,000 req/s | 100,000 req/s |
| **ì‘ë‹µ ì†ë„** | 2-5ì´ˆ | 200ms ì´í•˜ |
| **DB ë¶€í•˜** | ë†’ìŒ (ë½ ê²½í•©) | ë‚®ìŒ (ë¹„ë™ê¸° ì²˜ë¦¬) |
| **ì¥ì•  ë³µêµ¬** | ì–´ë ¤ì›€ (ë©”ì‹œì§€ ìœ ì‹¤) | ì‰¬ì›€ (ì¬ì²˜ë¦¬ ê°€ëŠ¥) |
| **í™•ì¥ì„±** | ìˆ˜ì§ í™•ì¥ë§Œ ê°€ëŠ¥ | ìˆ˜í‰ í™•ì¥ ìš©ì´ |
| **ìš´ì˜ ë³µì¡ë„** | ë‚®ìŒ | ì¤‘ê°„ (Kafka ê´€ë¦¬ í•„ìš”) |

### ì¶”ì²œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

âœ… **Kafka ì‚¬ìš© ì¶”ì²œ:**
- ì„ ì°©ìˆœ ì´ë²¤íŠ¸ (ì¿ í°, í‹°ì¼“, í•œì •íŒ ìƒí’ˆ)
- ëŒ€ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬ (ì´ˆë‹¹ 1ë§Œ ìš”ì²­ ì´ìƒ)
- ìˆœì„œ ë³´ì¥ì´ ì¤‘ìš”í•œ ê²½ìš°
- ë©”ì‹œì§€ ì¬ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš°

âŒ **Kafka ë¶ˆí•„ìš”:**
- ì‹¤ì‹œê°„ ë™ê¸° ì‘ë‹µì´ í•„ìˆ˜ì¸ ê²½ìš°
- íŠ¸ë˜í”½ì´ ì ì€ ê²½ìš° (ì´ˆë‹¹ 1000 ìš”ì²­ ë¯¸ë§Œ)
- ê°„ë‹¨í•œ ë¹„ë™ê¸° ì‘ì—… (Spring @Asyncë¡œ ì¶©ë¶„)

### ë‹¤ìŒ ë‹¨ê³„

1. **ë‹¨ê³„ë³„ ë„ì…:**
   - Phase 1: ì¿ í° ë°œê¸‰ë§Œ Kafkaë¡œ ì „í™˜
   - Phase 2: ëŒ€ê¸°ì—´ ì‹œìŠ¤í…œ ì¶”ê°€
   - Phase 3: ì „ì²´ ì£¼ë¬¸ í”Œë¡œìš° Kafka ì ìš©

2. **ëª¨ë‹ˆí„°ë§ ê°•í™”:**
   - Grafana ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
   - ì•ŒëŒ ê·œì¹™ ì„¤ì •
   - Consumer Lag ì¶”ì 

3. **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:**
   - ë¶€í•˜ í…ŒìŠ¤íŠ¸ (JMeter, Locust)
   - ì¥ì•  ì‹œë®¬ë ˆì´ì…˜ (Chaos Engineering)
   - íŠœë‹ ë° ìµœì í™”

---

**ì‘ì„±ì¼:** 2025-12-18
**ë²„ì „:** 1.0
**ì‘ì„±ì:** Claude Code
